# Асинхронный парсер PEP

## Описание проекта

**Асинхронный парсер PEP предназначен для автоматического сбора информации о PEP (Python Enhancement Proposals) с официального сайта Python (https://peps.python.org/). Основная задача парсера — собрать данные обо всех PEP, включая их номер, название и статус, а также сформировать сводку по статусам в формате CSV. Парсер реализован с использованием фреймворка Scrapy и применяет асинхронные методы для эффективного извлечения и обработки данных.**

## Установка и настройка

1. **Клонирование репозитория:**
    
    ```bash
    git clone git@github.com:closecodex/scrapy_parser_pep.git
    cd scrapy_parser_pep
    ```

2. **Создание и активация виртуального окружения:**

    ```bash
    python -m venv venv
    source venv\Scripts\activate
    ```

3. **Обновление менеджера пакетов и установка зависимостей:**
   
   ```bash
   python -m pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Запуск парсера:**

   ```bash
   scrapy crawl pep
   ```
   
## Результаты

1. **pep_ДатаВремя.csv: Содержит три столбца: number, name, status. Файл представляет собой список всех PEP с информацией о каждом из них.**

2. **status_summary_ДатаВремя.csv: Содержит два столбца: Статус, Количество. В файле указываются все возможные статусы PEP и количество PEP в каждом статусе. Последняя строка файла содержит общее количество всех документов (Total).**

## Дополнительная информация

1. **Автор: Мария Осмоловская (closecodex@github.com)**

2. **Техно-стек: Python, Scrapy, CSV.**